#!/usr/bin/env python3
#
# Copyright 2025 Darik Harter
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not use this
# file except in compliance with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software distributed under
# the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF
# ANY KIND, either express or implied.  See the License for the specific language
# governing permissions and limitations under the License.

import argparse
import json
import os
import readline
from dataclasses import dataclass
from openai import OpenAI
from openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam
from pathlib import Path
from rich.console import Console
from rich.live import Live
from rich.markdown import Markdown
from typing import Iterable, List

MODELS = (
    "gpt-4o-mini",
    "gpt-4o",
    "o1-mini",
)

SAVE_DIR = Path.home() / ".oai"

CLI_PROMPT = ">>> "
MULTI_LINE_INPUT = '"""'


@dataclass
class Settings:
    model: str
    pretty: bool


def send(
    client: OpenAI, settings: Settings, messages: Iterable[ChatCompletionMessageParam]
) -> str:
    stream = client.chat.completions.create(
        messages=messages,
        model=settings.model,
        stream=True,
    )

    content = ""
    if settings.pretty:
        with Live(console=Console(), refresh_per_second=8) as live:
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content += chunk.choices[0].delta.content
                    live.update(Markdown(content))
    else:
        for chunk in stream:
            if chunk.choices[0].delta.content:
                chunk_content = chunk.choices[0].delta.content
                print(chunk_content, end="")
                content += chunk_content
        print()
    return content


def get_api_key() -> str:
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key is None:
        raise RuntimeError("OPENAI_API_KEY environment variable is not set")
    return api_key


def get_user_input() -> str:
    user_input = input(CLI_PROMPT).strip()

    # Handle multi-line input.
    if user_input.startswith(MULTI_LINE_INPUT):
        lines = [user_input[len(MULTI_LINE_INPUT) :]]
        while True:
            line = input().rstrip()
            if line.endswith(MULTI_LINE_INPUT):
                lines.append(line[: -len(MULTI_LINE_INPUT)])
                break
            lines.append(line)
        user_input = "\n".join(lines).strip()

    return user_input.strip()


def print_help() -> None:
    print(
        "Available Commands:\n"
        "  /clear            Clear session context\n"
        "  /list             List available models\n"
        "  /select <model>   Select a model\n"
        "  /save <file>      Save conversation to a file\n"
        "  /load <file>      Load conversation from a file\n"
        "  /bye              Exit\n"
        "  /?, /help         Print available commands\n"
        "\n"
        f"Use {MULTI_LINE_INPUT} to begin a multi-line message."
    )


def print_models(settings: Settings) -> None:
    print("Available models:")
    for model in sorted(MODELS):
        prefix = " * " if model == settings.model else "   "
        print(f"{prefix}{model}")


def select_model(user_input: str, settings: Settings) -> None:
    parts = user_input.split()
    if len(parts) != 2:
        print("Usage:\n  /select <model>")
        return

    model = parts[1]

    if model not in MODELS:
        model_list = ", ".join(MODELS)
        print(f"Unknown model: '{model}'. Available models: {model_list}")
        return

    settings.model = model


def save_conversation(
    user_input: str, conversation: List[ChatCompletionMessageParam]
) -> None:
    parts = user_input.split()
    if len(parts) != 2:
        print("Usage:\n  /save <file>")
        return

    if not conversation:
        print("No conversation to save.")
        return

    filename = parts[1]
    if "/" in filename or "\\" in filename:
        print("Invalid filename.")
        return
    if not filename.endswith(".json"):
        filename += ".json"

    path = SAVE_DIR / filename
    if (
        path.exists()
        and input(f"File '{path}' already exists. Overwrite? (y/n) ").strip().lower()
        != "y"
    ):
        return

    SAVE_DIR.mkdir(parents=True, exist_ok=True)
    with open(path, "w") as save_file:
        json.dump(conversation, save_file, indent=4)
    print(f"\nSaved conversation to '{path}'.")


def load_conversation(
    user_input: str, conversation: List[ChatCompletionMessageParam], settings: Settings
) -> None:
    parts = user_input.split()
    if len(parts) != 2:
        print("Usage:\n  /load <file>")
        return

    filename = parts[1]
    if not filename.endswith(".json"):
        filename += ".json"

    path = SAVE_DIR / filename
    if not path.exists():
        print(f"File '{path}' does not exist.")
        return

    if (
        conversation
        and input("Overwrite current conversation? (y/n) ").strip().lower() != "y"
    ):
        return

    with open(path) as save_file:
        saved_conversation = json.load(save_file)

    conversation.clear()
    conversation.extend(saved_conversation)
    print_conversation(conversation, settings)


def print_conversation(
    conversation: List[ChatCompletionMessageParam], settings: Settings
) -> None:
    if not conversation:
        return

    for message in conversation:
        role = message["role"]
        content = message["content"]

        if role == "user":
            print(f"\n{CLI_PROMPT}{content}")
        else:
            if settings.pretty:
                Console().print(Markdown(content))
            else:
                print(content)


def handle_command(
    user_input: str, conversation: List[ChatCompletionMessageParam], settings: Settings
) -> None:
    command = user_input.split()[0]

    if command == "/bye":
        raise EOFError
    elif command == "/clear":
        conversation.clear()
        print("Cleared conversation.")
    elif command == "/list":
        print_models(settings)
    elif command == "/load":
        load_conversation(user_input, conversation, settings)
    elif command == "/save":
        save_conversation(user_input, conversation)
    elif command == "/select":
        select_model(user_input, settings)
    elif command == "/?" or command == "/help":
        print_help()
    else:
        print(f"Unknown command: '{command}'. Type /? for help.")

    print()


def input_loop(client: OpenAI, settings: Settings) -> None:
    conversation = []
    readline.parse_and_bind("set editing-mode emacs")

    while True:
        try:
            user_input = get_user_input().strip()
            if not user_input:
                continue

            if user_input.startswith("/"):
                handle_command(user_input, conversation, settings)
                continue

        except EOFError:
            break

        conversation.append({"role": "user", "content": user_input})

        try:
            reply = send(client, settings, conversation)
            conversation.append({"role": "assistant", "content": reply})
        except Exception as e:
            print(f"Error: {e}")

        print()


def get_available_models(client: OpenAI) -> List[str]:
    return [model.id for model in client.models.list()]


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Chat with OpenAI LLMs in the terminal",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "--model", default="gpt-4o-mini", choices=MODELS, help="the OpenAI model to use"
    )
    parser.add_argument("--pretty", action="store_true", help="pretty print responses")
    args = parser.parse_args()
    input_loop(OpenAI(api_key=get_api_key()), Settings(args.model, args.pretty))


if __name__ == "__main__":
    main()
